{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bf55b-37a5-4fde-9a87-d57855a4ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python module for MJO diagnostics \n",
    "# Lisa Neef, 27 Jan 2015\n",
    "\n",
    "# to find the Pyclimate package that works for this version of Python, need to append this odd path to the system path.\\n\",\n",
    "import sys\n",
    "sys.path.append(\"/home/lneef/anaconda/pkg/lib/python/\") \n",
    "\n",
    "# load the required packages  \n",
    "import numpy as np\n",
    "import datetime\n",
    "import time as time\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import DART as dart\n",
    "import experiment_settings as es\n",
    "#from calendar import monthrange\n",
    "#from netCDF4 import Dataset\n",
    "import WACCM as waccm\n",
    "import DART_state_space as DSS\n",
    "import pyclimate.LanczosFilter as LF\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import nanmean\n",
    "\n",
    "\n",
    "def plot_RMM(E,copies_to_plot,climatology_option='NODA',plot_type='polar',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tgiven a certain experiment dictionary, compute the Wheeler and Hendon (2004)\n",
    "\tRMM index (by projecting the modeled fields onto Wheeler and Hendon's multivariate EOFs),\n",
    "\twith or without the \"true\" (i.e. operational) value.  \n",
    "\n",
    "\tINPUTS:\n",
    "\tcopies_to_plot: list containing keywords for what copies to plot. Here are the options:  \n",
    "\t\t+ any valid copystring in DART output data  (e.g. \"ensemble member 1\")\n",
    "\t\t+ 'ensemble' = plot the entire ensemble  \n",
    "\t\t+ 'ensemble mean' = plot the ensemble mean  \n",
    "\t\t+ 'operational' = plot the operational value of this index \n",
    "\tclimatology_option: options for how to compute the climatology needed for anomaly computation: \n",
    "\t\t+ 'NODA'  - use the analogue for the desired experiment that has no assimilation  \n",
    "\t\t+ 'F_W4_L66' - WACCM run with F_W4_L66 compset  \n",
    "\tplot_type: choose 'polar' to draw the standard RMM circle diagram, or 'linear' to plot \n",
    "\t\tthe two components linearly \n",
    "\t\"\"\"\n",
    "\n",
    "\t# given the chosen plot variation, define a list of copies to load\n",
    "\tcopy_list = []\n",
    "\n",
    "\tif \"copystring\" in copies_to_plot:\n",
    "\t\tcopy_list.append(E['copystring'])\n",
    "\n",
    "\tif (\"ensemble\" in copies_to_plot): \n",
    "\t\tN = es.get_ensemble_size_per_run(E['exp_name'])\n",
    "\t\tfor iens in np.arange(1,N+1):\n",
    "\t\t\tif iens < 10:\n",
    "\t\t\t\tspacing = '      '\n",
    "\t\t\telse:\n",
    "\t\t\t\tspacing = '     '\n",
    "\t\t\tcopy_list.append(\"ensemble member\"+spacing+str(iens))\t\t\n",
    "\tif (\"ensemble mean\" in copies_to_plot): \n",
    "\t\t\tcopy_list.append(\"ensemble mean\")\n",
    "\tif (\"operational\" in copies_to_plot): \n",
    "\t\t\tcopy_list.append(\"operational\")\n",
    "\n",
    "\t# compute the PCs for the desired timespan and list of copies \n",
    "\t# or load the observatinal value \n",
    "\tRMM1list = []\n",
    "\tRMM2list = []\n",
    "\tbad_copies = []\t\t# start a list of the copies that are unavailable  \n",
    "\tfor copy in copy_list:\n",
    "\n",
    "\t\tprint(copy)\n",
    "\t\tif copy == \"operational\":\n",
    "\t\t\tdate_limits = (E['daterange'][0],E['daterange'][len(E['daterange'])-1])\n",
    "\t\t\tdates,RMM1,RMM2 = read_RMM_true(date_limits,hostname='taurus')\n",
    "\t\t\tRMM1list.append(RMM1)\n",
    "\t\t\tRMM2list.append(RMM2)\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tE['copystring'] = copy\n",
    "\t\t\tpc = RMM(E,climatology_option=climatology_option,hostname='taurus',verbose=verbose)\n",
    "\t\t\tif pc is None:\n",
    "\t\t\t\t# if we don't have enough data to compute the RMM index for this experiment, \n",
    "\t\t\t\t# add it to the list of bad copies:\n",
    "\t\t\t\tprint('     Unable to compute RMM index for '+copy)\n",
    "\t\t\t\tbad_copies.append(copy)\n",
    "\t\t\telse:\n",
    "\t\t\t\tRMM1list.append(pc[0,:])\n",
    "\t\t\t\tRMM2list.append(pc[1,:])\n",
    "\n",
    "\t# remove the \"bad\" copies from the list\n",
    "\t[copy_list.remove(bc) for bc in bad_copies]\n",
    "\n",
    "\tif plot_type == 'polar':\n",
    "\t\t# pimp out the plot a little bit  \n",
    "\t\tplt.plot([-4,4],[-4,4],linewidth=0.2,linestyle='--',color='k')\n",
    "\t\tplt.plot([-4,4],[4,-4],linewidth=0.2,linestyle='--',color='k')\n",
    "\t\tplt.plot([-4,4],[0,0],linewidth=0.2,linestyle='--',color='k')\n",
    "\t\tplt.plot([0,0],[-4,4],linewidth=0.2,linestyle='--',color='k')\n",
    "\t\tplt.xlim([-4.0,4.0])\n",
    "\t\tplt.ylim([-4.0,4.0])\n",
    "\n",
    "\t\t# circle in the center of the plot to denote weak index  \n",
    "\t\tcircle = plt.Circle((0, 0), radius=1.0, fc='k', ec='k', alpha=0.2)\n",
    "\t\tplt.gca().add_patch(circle)\n",
    "\n",
    "\t# cycle over copies and plot the two princial components against each other  \n",
    "\tfor copy,RMM1,RMM2 in zip(copy_list,RMM1list,RMM2list):\n",
    "\t\t\n",
    "\t\t# choose the color based on the copy string\n",
    "\t\tif \"ensemble member\" in copy:\n",
    "\t\t\tlcolor = \"#848484\"\n",
    "\t\t\talph=0.8\n",
    "\t\t\ttime = E['daterange']\n",
    "\t\tif copy == \"ensemble mean\":\n",
    "\t\t\tlcolor = \"#70B8FF\"\n",
    "\t\t\talph=1.0\n",
    "\t\t\ttime = E['daterange']\n",
    "\t\tif copy == \"operational\":\n",
    "\t\t\tlcolor = \"#000000\"\n",
    "\t\t\talph=1.0\n",
    "\t\t\ttime=dates\n",
    "\n",
    "\t\t# plot desired copy\n",
    "\t\tif plot_type=='polar':\n",
    "\t\t\tplt.plot(RMM1,RMM2,'-',color=lcolor,alpha=alph)\n",
    "\t\tif plot_type=='RMM1':\n",
    "\t\t\tplt.plot(time,RMM1,'-',color=lcolor,alpha=alph)\n",
    "\t\tif plot_type=='RMM2':\n",
    "\t\t\tplt.plot(time,RMM2,'-',color=lcolor,alpha=alph)\n",
    "\t\tif plot_type=='linear':\n",
    "\t\t\tplt.subplot(2,1,1)\n",
    "\t\t\tplt.plot(time,RMM1,'-',color=lcolor,alpha=alph)\n",
    "\t\t\tplt.subplot(2,1,2)\n",
    "\t\t\tplt.plot(time,RMM2,'-',color=lcolor,alpha=alph)\n",
    "\n",
    "\t# labels and stuff  \n",
    "\tplt.xlabel('RMM1')\n",
    "\tplt.ylabel('RMM2')\n",
    "\n",
    "\treturn copy,RMM1,RMM2\n",
    "\n",
    "def compute_RMM_to_pandas_dataframe(E,copies_to_plot,climatology_option='NODA',plot_type='polar',hostname='taurus',verbose=False):\n",
    "\n",
    "\treturn\n",
    "\n",
    "def plot_correlations_lag_lat_or_lon(E,climatology_option='NODA',maxlag=25,lag_versus_what='lon',nilter_order=50,cbar=True,hostname=\"taurus\",debug=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\t given a certain experiment or dataset over a certain daterange, \n",
    "\t plot the correlation between wind or precip anomalies in one reference\n",
    "\t region, relative to everywhere else, either \n",
    "\t as a function of latitude and longite, and Lag.  \n",
    "\t this should produce figures like Figs. 5-6 of Waliser et al. \n",
    "\n",
    "\tINPUTS:  \n",
    "\tE - a standard DART experiment dictionary, with the variable field and level range corresponding to some MJO variable  \n",
    "\tmaxlag: the limit of the lag (in days) that we look at \n",
    "\tlag_versus_what: choose 'lat' or 'lon'  \n",
    "\tcbar: set to True to have a colorbar  \n",
    "\thostname: computer name - default is Taurus  \n",
    "\tclimatology_option: choose which climatology to take the anomalies to respect with -- default is \"NODA\"  \n",
    "\t\"\"\"\n",
    "\n",
    "\t# load the correlation field \n",
    "\tR,S,L,x = correlations_lag_lat_or_lon(E,maxlag,lag_versus_what,filter_order,climatology_option,hostname=hostname,verbose=debug)\n",
    "\n",
    "        # choose color map based on the variable in question\n",
    "\tE['extras'] = 'Correlation'\n",
    "\tcolors,cmap,cmap_type = DSS.state_space_HCL_colormap(E,reverse=True)\n",
    "\t\n",
    "\t# choose axis labels  \n",
    "\tplt.ylabel('Lag (days)')\n",
    "\tif lag_versus_what=='lat':\n",
    "\t\tplt.xlabel('Latitude')\n",
    "\tif lag_versus_what=='lon':\n",
    "\t\tplt.xlabel('Longitude')\n",
    "\n",
    "\t# set the contour levels - it depends on the color limits and the number of colors we have  \n",
    "\tclim = 1.0\n",
    "\tif cmap_type == 'divergent':\n",
    "\t\tclevels  = np.linspace(start=-clim,stop=clim,num=11)\n",
    "\telse:\n",
    "\t\tclevels  = np.linspace(start=0,stop=clim,num=11)\n",
    "\n",
    "        # contour plot of the chosen variable\n",
    "\tcs = plt.contourf(x,L,R,levels=clevels,cmap=cmap)\n",
    "\tplt.clim([-1.0,1.0])\n",
    "\n",
    "\tif (cbar is not None):\n",
    "\t\tCB = plt.colorbar(cs, shrink=0.6, extend='both', orientation=cbar)\n",
    "\n",
    "\treturn x,L,R,S\n",
    "\n",
    "def plot_variance_maps(E,cbar=True,hostname=\"taurus\"):\n",
    "\n",
    "\t# given a certain experiment or dataset over a certain daterange, \n",
    "\t# plot the MJO-related variance on a map\n",
    "\n",
    "\t# load the variance map  \n",
    "\tVV,lat,lon = variance_maps(E,hostname=hostname)  \n",
    "\n",
    " \t# set up the  map projection\n",
    "\tmap = Basemap(projection='mill',llcrnrlat=-90,urcrnrlat=90,\\\n",
    "\t\t    #llcrnrlon=-180,urcrnrlon=180,resolution='c')\n",
    "\t\t    llcrnrlon=0,urcrnrlon=360,resolution='c')\n",
    "\n",
    "        # draw coastlines, country boundaries, fill continents.\n",
    "\tmap.drawcoastlines(linewidth=0.25)\n",
    "\tmap.drawcountries(linewidth=0.25)\n",
    "\n",
    "        # draw lat/lon grid lines every 30 degrees.\n",
    "\tmap.drawmeridians(np.arange(0,360,30),linewidth=0.25)\n",
    "\tmap.drawparallels(np.arange(-90,90,30),linewidth=0.25)\n",
    "\n",
    "        # compute native map projection coordinates of lat/lon grid.\n",
    "\tX,Y = np.meshgrid(lon,lat)\n",
    "\tx, y = map(X, Y)\n",
    "\n",
    "        # choose color map based on the variable in question\n",
    "\tE['extras'] = 'MJO variance'\n",
    "\tcolors,cmap,cmap_type = DSS.state_space_HCL_colormap(E)\n",
    "\n",
    "\t## if no color limits are specified, at least make them even on each side\n",
    "        #if clim is None:\n",
    "        #        clim = np.nanmax(np.absolute(VV))\n",
    "\t#print('------clim----------')\n",
    "\t#print(clim)\n",
    "\n",
    "\n",
    "        # contour data over the map.\n",
    "\tcs = map.contourf(x,y,VV,15,cmap=cmap)\n",
    "\t#cs = map.contourf(x,y,M,len(colors)-1,colors=colors)\n",
    "\t#cs = map.contourf(X,Y,M,len(colors)-1,cmap=cmap,extend=\"both\",vmin=-clim,vmax=clim)\n",
    "\n",
    "\t# apply color limits, but not if it's a log contour plot\n",
    "\t#if log_levels is None:\n",
    "\t#\tprint('applying color limits')\n",
    "\t#\tif cmap_type == 'divergent':\n",
    "\t#\t\tplt.clim([-clim,clim])\n",
    "\t#\telse:\n",
    "\t#\t\tplt.clim([0,clim])\n",
    "\n",
    "\t#if cbar:\n",
    "\t#\tif (clim > 1000):\n",
    "\t#\t\tCB = plt.colorbar(cs, shrink=0.6, extend='both',format='%.1e')\n",
    "\t#\tif (clim < 0.001):\n",
    "\t#\t\tCB = plt.colorbar(cs, shrink=0.6, extend='both',format='%.1e')\n",
    "\t#\telse:\n",
    "\tCB = plt.colorbar(cs, shrink=0.6, extend='both')\n",
    "\n",
    "\n",
    "def variance_maps(E,climatology_option = 'NODA',hostname='taurus',verbose=False):  \n",
    "\n",
    "\t# given a certain experiment or dataset (E) over a certain daterange,  \n",
    "\t# retrieve the data, then \n",
    "\t# calculate the daily climatology and anomaly wrt climatology, \n",
    "\t# then filter the daily anomaly using a Lanczos filter, \n",
    "\t# then calculate the variance of the filtered anomaly.  \n",
    "\t# based on code from the CLIVAR MJO diagnostics, \n",
    "\n",
    "\t# make sure that the vertical level range is set to something around 850 hPa\n",
    "\t# the vertical levels we select depend on the model\n",
    "\t# **right now only have settings for L66 WACCM\n",
    "\tE['levrange'] = [850,850]\n",
    "\n",
    "\t# compute or load the daily climatology and deviation from climatology  \n",
    "\tanomalies,climatology,lat,lon,lev = ano(E,climatology_option = climatology_option,hostname=hostname,verbose=verbose)\n",
    "\n",
    "\t# filter daily anomalies using a Lanczos filter\n",
    "\tAA,FA = filter(anomalies,return_as_vector=True)\n",
    "\n",
    "\t# compute the variance of these filtered anomaly fields\n",
    "\tVV = var(AA,variable_dimensions=anomalies.shape,return_as_vector=False)\n",
    "\n",
    "\treturn VV,lat,lon\n",
    "\n",
    "def correlations_lag_lat_or_lon(E,maxlag,lat_or_lon = 'lon',filter_order=50,climatology_option='NODA',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tcompute correlations between U850 or OLR in a reference are and everywhere else, \n",
    "\tas a function of lag and either latitude or longitude \n",
    "\n",
    "\tINPUTS:  \n",
    "\tE - a standard DART experiment dictionary, with the variable field and level range corresponding to some MJO variable  \n",
    "\tmaxlag: the limit of the lag (in days) that we look at \n",
    "\tlat_or_lon: choose dimension to preserve after averaging -- 'lat' or 'lon'  \n",
    "\tclimatology_option: choose which climatology to take the anomalies to respect with -- default is \"NODA\"  \n",
    "\t\"\"\"\n",
    "\n",
    "\t# change the given daterange to daily resolution, because the lag is specified in days  \n",
    "\tE['daterange'] = dart.change_daterange_to_daily(E['daterange'])\n",
    "\n",
    "\t# compute or load the daily climatology and deviation from climatology  \n",
    "\tanomalies,climatology,lat,lon,lev,DRnew = ano(E,climatology_option = climatology_option,hostname=hostname,verbose=verbose)\n",
    "\n",
    "\t# filter daily anomalies using a Lanczos filter\n",
    "\tAA,FA = filter(anomalies,filter_order,return_as_vector=False)\n",
    "\t\n",
    "\tif E['variable'] == 'U':\n",
    "\t\tvariable_name = 'U'+str(E['levrange'][0])\n",
    "\telse:\n",
    "\t\tvariable_name = E['variable']\n",
    "\n",
    "\t# compute the zonal and meridional mean of the resulting field \n",
    "\t# the regions we average over depend on whether we want lag-lat, or lag-lon plots\n",
    "\t# also, note thatm by how the filtered anomalies are constructed, the 3rd dimension is always time  \n",
    "\tif lat_or_lon == \"lon\":\n",
    "\t\t# select latitudes 10S-10N and average meridionally, then plot correlations as a function of lon  \t\n",
    "\t\tlat1,lon1,FAm = aave('TB',FA,lat,lon,None,variable_name,averaging_dimension='lat')\n",
    "\tif lat_or_lon == \"lat\":\n",
    "\t\t# average over the longitude corridor 80-100E and plot correlations as a function of lat\n",
    "\t\tlat1,lon1,FAm = aave('ZB',FA,lat,lon,None,variable_name,averaging_dimension='lon')\n",
    "\n",
    "\n",
    "\t# area averaging  the desired variable over the Indian Ocean reference point\n",
    "\tif (E['daterange'][0].month  >= 10) or (E['daterange'][0].month  <= 2):\n",
    "\t\tseason = 'winter'\n",
    "\telse:\n",
    "\t\tseason = 'summer'\n",
    "\tlat0,lon0,FA0 = aave('IO',FA,lat,lon,season,variable_name,averaging_dimension=\"all\")\n",
    "\n",
    "\t#------ compute field of correlation coefficients   \t\n",
    "\t# empty array size Lag by Lat\n",
    "\t# plus an array to keep track of sample size\n",
    "\tLag_range = range(-maxlag,maxlag+1)\n",
    "\tnlag = len(Lag_range)\n",
    "\tn = FAm.shape[0]\n",
    "\tR = np.zeros(shape=(nlag,n))\n",
    "\tS = np.zeros(shape=(nlag,n))\n",
    "\n",
    "\t# loop over latitudes\n",
    "\tT = len(FA0)\n",
    "\tfor ii in range(n):\n",
    "\t\t# loop over lags  \n",
    "\t\tfor ilag,L in zip(range(nlag),Lag_range):\n",
    "\t\t\t# the time points that we can check go from L to T-L\n",
    "\t\t\t# so shorter lags have a larger sample size and are more significant.  \n",
    "\t\t\tif L < 0:\n",
    "\t\t\t\tTsel = range(-L,T)\n",
    "\t\t\tif L > 0:\n",
    "\t\t\t\tTsel = range(0,T-L)\n",
    "\t\t\tif L == 0:\n",
    "\t\t\t\tTsel = range(0,T)\n",
    "\n",
    "\t\t\t# loop over the available time points and gather values to compare\n",
    "\t\t\tIO = []\n",
    "\t\t\tX  = []\n",
    "\t\t\tfor k in Tsel:\n",
    "\t\t\t\tIO.append(FA0[k+L])\n",
    "\t\t\t\tX.append(FAm[ii,k])\n",
    "\n",
    "\t\t\t# now compute the correlation from this list of samples and store in the lag vs lat array  \n",
    "\t\t\trho = np.corrcoef(X,IO)\n",
    "\t\t\tif rho != []:\n",
    "\t\t\t\tR[ilag,ii] = rho[1,0]\n",
    "\t\t\t\tS[ilag,ii] = len(IO)\n",
    "\t\t\telse:\n",
    "\t\t\t\tR[ilag,ii] = np.nan\n",
    "\t\t\t\tS[ilag,ii] = np.nan\n",
    "\tif lat_or_lon == 'lon':\n",
    "\t\tspace_dim = lon1\n",
    "\tif lat_or_lon == 'lat':\n",
    "\t\tspace_dim = lat1\n",
    "\n",
    "\tL = np.array(Lag_range)\n",
    "\n",
    "\treturn R,S,L,space_dim\n",
    "\n",
    "def RMM(E,climatology_option = 'NODA',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tthis subroutine computes the real-time multivariate MJO (RMM) indices defined by Wheeler and Hendon (2004)\n",
    "\tthis is done by reading in the multivariate EOF of OLR, U850, and U200 (computed from \n",
    "\tsatellite data and NCEP reanalysis), and then projecting our model's anomaly \n",
    "\tfields onto these EOFs.  \n",
    "\n",
    "\tThis code is pretty clunky, because it computes the RMM index over the daterange in E['daterange'], but \n",
    "\tit uses all available data in the experiment given by E to compute the standard deviations of anomalies in \n",
    "\teach variable. -- so it's best to run this all at once over long spans of time.  \n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\t# read in the multivariate EOFs (eigenvectors)  \n",
    "\tif hostname == 'taurus':\n",
    "\t\tdata_dir = '/data/c1/lneef/MJOindex/'\n",
    "\tfname = 'WH04_EOFstruc.txt'  \n",
    "\tff = data_dir+fname  \n",
    "\n",
    "\tEVEC = pd.read_csv(ff,sep=' ',skiprows=9,nrows=432,header=None,engine='python')\n",
    "\tEVEC.columns=['blank','EV1','EV2']\n",
    "\tEOF = [EVEC.EV1, EVEC.EV2]\n",
    "\n",
    "\t# read in the normalization factors  \n",
    "\tNORM = pd.read_csv(ff,skiprows=442,sep='  ',engine='python')\n",
    "\tNORM.columns = ['normalization_factors']  \n",
    "\tnormfac = NORM.normalization_factors\n",
    "\tNF_FLUT = normfac[0:144]\n",
    "\tNF_U850 = normfac[144:288]\n",
    "\tNF_U200 = normfac[288:432]\n",
    "\tNF_list = [NF_FLUT,NF_U850,NF_U200]\n",
    "\n",
    "\t# read in the eigenvalues  \n",
    "\tf = open(ff, \"r\")\n",
    "\tlines = f.readlines()\n",
    "\teigenvalues = lines[4].split()\n",
    "\teigenval1 = float(eigenvalues[0])\n",
    "\teigenval2 = float(eigenvalues[1])\n",
    "\tevalues = [eigenval1,eigenval2]\n",
    "\tf.close()\n",
    "\t\n",
    "\t# load anomalies of the three MJO variable (OLR, U850, U200) for this experiment\n",
    "\tvariable_list = ['FLUT','U','U']\n",
    "\tlevrange_list = [None,[850,850],[200,200]]\n",
    "\tAnomaly_list = []\n",
    "\tfor variable,levrange,NF in zip(variable_list,levrange_list,NF_list):\n",
    "\t\tEtemp = E.copy()\n",
    "\t\tEtemp['variable'] = variable\n",
    "\t\tEtemp['levrange'] = levrange\n",
    "\n",
    "\t\t# for the MJO, we are only interested in anomalies between 15S and 15N\n",
    "\t\tEtemp['latrange'] = [-15,15]\n",
    "\n",
    "\t\tif Etemp['variable'] == 'U':\n",
    "\t\t\tvariable_name = 'U'+str(levrange[0])\n",
    "\t\telse:\n",
    "\t\t\tvariable_name = Etemp['variable']\n",
    "\n",
    "\t\t# load variable anomaly field for each variable\n",
    "\t\tanomalies,climatology,lat,lon,lev,DRnew = ano(Etemp,climatology_option=climatology_option,hostname=hostname,verbose=verbose)\n",
    "\t\tif anomalies is None:\n",
    "\t\t\tprint('not enough data to compute RMM index -- returning')\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\t# average the normalized anomalies over the 15S-15N latitude band  \n",
    "\t\tlat1,lon1,ave_anom = aave('WH',anomalies,lat,lon,None,variable_name,averaging_dimension='lat')\n",
    "\n",
    "\t\t# normalize the anoamlies of each variable field by its standard deviation \n",
    "\t\t#if climatology_option=='NODA':\n",
    "\t\t\t# if we want standard deviations given by the No-DA experiment, do that here \n",
    "\t\t\t# TODO: subroutine that loads correposnind No-DA experiment for a given experiment \n",
    "\t\t#\tEtemp = E.copy()\n",
    "\t\t#\tEtemp['exp_name'] = 'W0910_NODA'\n",
    "\t\t#\tS,lat,lon,lev,DR = load_std(Etemp,'ensemble',hostname)\n",
    "\t\t#else:\n",
    "\t\t#\tS,lat,lon,lev,DR = load_std(E,climatology_option,hostname)\n",
    "\n",
    "\t\t# the compute the \"global\" std for that variable (it's actually over the vertical and \n",
    "\t\t# horizontal domain given in E)\n",
    "\t\t#std = np.nanmean(S)\n",
    "\n",
    "\t\t# for each time in the array of anomalies, divide out the normalization factor for each MJO variable  \n",
    "\t\t# if anomalies were only computed for a single day, it's even simpler\n",
    "\t\tanomshape = np.squeeze(ave_anom).shape\n",
    "\t\tif len(anomshape) > 2:\n",
    "\t\t\tnT = np.squeeze(ave_anom).shape[1]\n",
    "\t\t\tave_anom_norm = 0*ave_anom\n",
    "\t\t\tfor aa,iT in zip(ave_anom,range(nT)):\n",
    "\t\t\t\t#ave_anom_norm[:,iT] = np.squeeze(ave_anom[:,iT])/std\n",
    "\t\t\t\tave_anom_norm[:,iT] = np.squeeze(ave_anom[:,iT])/NF\n",
    "\t\telse:\n",
    "\t\t\tave_anom_norm = np.squeeze(ave_anom)/NF\n",
    "\t\t\tnT = None\n",
    "\n",
    "\t\t# put everything into a list\n",
    "\t\tAnomaly_list.append(ave_anom_norm)\n",
    "\n",
    "\n",
    "\t# concatenate the 3 anomaly fields so that we have a length (144x3) vector for nT points in time  \n",
    "\tAA = np.concatenate([A for A in Anomaly_list], axis=0)\n",
    "\n",
    "\t# compute the principal components  \n",
    "\tN = EVEC.EV1.shape[0]\n",
    "\tif nT is None:\n",
    "\t\tpc = np.zeros(shape=(2))\n",
    "\t\t# loop over eigenvalues and then over 3x longitudes\n",
    "\t\tfor eof,iev,eigval in zip(EOF,range(2),evalues):\t# loop over eigenvectors and eigenvalues\n",
    "\t\t\tfor ii in range(N):\t\t\t\t# loop over 3xlongitudes  \n",
    "\t\t\t\tpc[iev] += (AA[ii]*eof[ii])/np.sqrt(eigval)\n",
    "\telse:\n",
    "\t\tpc = np.zeros(shape=(2,nT))\n",
    "\t\tfor k in range(nT):\t# loop over time  \n",
    "\t\t\tfor eof,iev,eigval in zip(EOF,range(2),evalues):\t# loop over eigenvectors and eigenvalues\n",
    "\t\t\t\tfor ii in range(N):\t\t\t\t# loop over 3xlongitudes  \n",
    "\t\t\t\t\tpc[iev,k] += (AA[ii,k]*eof[ii])/np.sqrt(eigval)\n",
    "\n",
    "\treturn pc\n",
    "\n",
    "def load_climatology(E,climatology_option = 'NODA',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tLoad a climatology option for a given DART experiment. \n",
    "\tThe choice of climatology is given by 'climatology_option'. Choices are:  \n",
    "\t'NODA' (default): take the ensemble mean of the corresponding no-DA experiment as a N-year climatology  \n",
    "\t'F_W4_L66': CESM-WACCM simulation with observed forcings, 1951-2010 (perfomed by Wuke Wang)  \n",
    "\t\"\"\"\n",
    "\tclimatology_option_not_found = True\n",
    "\n",
    "\tif climatology_option == 'NODA' :\n",
    "\t\tclimatology_option_not_found = False\n",
    "\t\t# cycle over the dates in the experiment dictionary \n",
    "\t\t# and load the ensemble mean of the corresponding No-assimilation case \n",
    "\t\t# TODO: a subroutine that returns the corresponding NODA experiment for each case  \n",
    "\t\tXlist = []\t\n",
    "\t\tECLIM = E.copy()\n",
    "\t\tECLIM['exp_name'] = 'W0910_NODA'\n",
    "\t\tECLIM['diagn'] = 'Prior'\n",
    "\t\tECLIM['copystring'] = 'ensemble mean'\n",
    "\t\tXclim,lat,lon,lev,DRnew = DSS.DART_diagn_to_array(ECLIM,hostname=hostname,debug=verbose)\n",
    "\t\tif len(DRnew) != len(ECLIM['daterange']):\n",
    "\t\t\tprint('NOTE: not all requested data were found; returning a revised datarange')\n",
    "\t\tif Xclim is None:\n",
    "\t\t\tprint('Cannot find data for climatology option '+climatology_option+' and experiment '+E['exp_name'])\n",
    "\t\t\treturn None, None, None, None\n",
    "\n",
    "\tif climatology_option == 'F_W4_L66' :\n",
    "\t\tfrom netCDF4 import Dataset\n",
    "\t\tclimatology_option_not_found = False\n",
    "\t\t# in this case, load a single daily climatology calculated from this CESM-WACCM simulation  \n",
    "\t\tff = '/data/c1/lneef/CESM/F_W4_L66/atm/climatology/F_W4_L66.cam.h1.1951-2010.daily_climatology.nc'\n",
    "\t\tf = Dataset(ff,'r')\n",
    "\t\tlat = f.variables['lat'][:]\n",
    "\t\tlon = f.variables['lon'][:]\n",
    "\t\tlev = f.variables['lev'][:]\n",
    "\t\ttime = f.variables['time'][:]\n",
    "\n",
    "\t\t# load climatology of the desired model variable  \n",
    "\t\tvariable = E['variable']\n",
    "\t\tif E['variable'] == 'US':\n",
    "\t\t\tvariable = 'U'\n",
    "\t\tif E['variable'] == 'VS':\n",
    "\t\t\tvariable = 'V'\n",
    "\t\tif E['variable'] == 'OLR':\n",
    "\t\t\tvariable = 'FLUT'\n",
    "\t\tVV = f.variables[variable][:]\n",
    "\t\tf.close()\n",
    "\n",
    "\t\t# choose the times corresponding to the daterange in E\n",
    "\t\td0 = E['daterange'][0].timetuple().tm_yday\t# day in the year where we start  \n",
    "\t\tnT = len(E['daterange'])\n",
    "\t\tdf = E['daterange'][nT-1].timetuple().tm_yday\t# day in the year where we start  \n",
    "\n",
    "\t\t# if df<d0, we have to cycle back to the beginning of the year\n",
    "\t\tif df < d0:\n",
    "\t\t\tday_indices = list(range(d0-1,365))+list(range(0,df))\n",
    "\t\telse:\n",
    "\t\t\tday_indices = list(range(d0-1,df))\n",
    "\n",
    "\t\t# also choose the lat, lon, and level ranges corresponding to those in E\n",
    "\t\tif E['levrange'] is not None:\n",
    "\t\t\tif E['levrange'][0] == E['levrange'][1]:\n",
    "\t\t\t\tll = E['levrange'][0]\n",
    "\t\t\t\tidx = (np.abs(lev-ll)).argmin()\n",
    "\t\t\t\tlev2 = lev[idx]\n",
    "\t\t\t\tk1 = idx\n",
    "\t\t\t\tk2 = idx\n",
    "\t\t\telse:\n",
    "\t\t\t\thighest_level_index = (np.abs(lev-E['levrange'][1])).argmin()\n",
    "\t\t\t\tlowest_level_index = (np.abs(lev-E['levrange'][0])).argmin()\n",
    "\t\t\t\t# which index is k1 or k2 depends on the direction of lev \n",
    "\t\t\t\tif highest_level_index > lowest_level_index:\n",
    "\t\t\t\t\tk2 = highest_level_index\n",
    "\t\t\t\t\tk1 = lowest_level_index\n",
    "\t\t\t\tif highest_level_index < lowest_level_index:\n",
    "\t\t\t\t\tk1 = highest_level_index\n",
    "\t\t\t\t\tk2 = lowest_level_index\n",
    "\t\t\t\tlev2 = lev[k1:k2+1]\n",
    "\n",
    "\t\tj2 = (np.abs(lat-E['latrange'][1])).argmin()\n",
    "\t\tj1 = (np.abs(lat-E['latrange'][0])).argmin()\n",
    "\t\tlat2 = lat[j1:j2+1]\n",
    "\t\ti2 = (np.abs(lon-E['lonrange'][1])).argmin()\n",
    "\t\ti1 = (np.abs(lon-E['lonrange'][0])).argmin()\n",
    "\t\tlon2 = lon[i1:i2+1]\n",
    "\n",
    "\t\tif len(VV.shape) == 4:\n",
    "\t\t\tXclim = VV[day_indices,k1:k2+1,j1:j2+1,i1:i2+1]\n",
    "\t\telse:\n",
    "\t\t\tXclim = VV[day_indices,j1:j2+1,i1:i2+1]\n",
    "\n",
    "\t\t# in this case, we don't need to change the daterange  \n",
    "\t\tDRnew = E['daterange']\n",
    "\n",
    "\tif climatology_option_not_found:\n",
    "\t\tprint('Climatology option '+climatology_option+' has not been coded yet. Returning None for climatology.')\n",
    "\t\treturn None, None, None, None\n",
    "\n",
    "\treturn Xclim,lat,lon,lev,DRnew\n",
    "\n",
    "def load_std(E,std_mode = 'NODA',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tThis subroutine returns the standard deviation of whatever variable is given in E['variable'], \n",
    "\tfor each time given in E['daterange'].\n",
    "\tThere are several ways to compute the standard deviation, and that's determined by the input \n",
    "\t'std_mode':\n",
    "\t\tstd_mode='ensemble' simply computes the standard deviation of the DART ensemble  \n",
    "\t\t\tat each time \n",
    "\t\tif you set std_mode to any other string, it looks up the multi-year experiment corresponding \n",
    "\t\t\tto that string using the subroutine 'std_runs' in the user \n",
    "\t\t\tmodule experiment_settings. \n",
    "\t\t\tIn this case, the standard deviation  \n",
    "\t\t\tis computed for each time over several years, rather than an ensemble \n",
    "\n",
    "\t\"\"\"\n",
    "\tif std_mode == 'ensemble' :\n",
    "\t\t# cycle over the dates in the experiment dictionary \n",
    "\t\t# and load the ensemble mean of the corresponding No-assimilation case \n",
    "\t\t# TODO: a subroutine that returns the corresponding NODA experiment for each case  \n",
    "\t\tXlist = []\t\n",
    "\t\tECLIM = E.copy()\n",
    "\t\tECLIM['copystring'] = 'ensemble std'\n",
    "\t\tXclim,lat,lon,lev,DRnew = DSS.DART_diagn_to_array(ECLIM,hostname=hostname,debug=verbose)\n",
    "\t\tif len(DRnew) != len(ECLIM['daterange']):\n",
    "\t\t\tprint('NOTE: not all requested data were found; returning a revised datarange')\n",
    "\t\tif Xclim is None:\n",
    "\t\t\tprint('Cannot find data for experiment '+E['exp_name'])\n",
    "\t\t\treturn None, None, None, None\n",
    "\n",
    "\tif std_mode == 'F_W4_L66' :\n",
    "\n",
    "\t\t# find the corresponding dataset  \n",
    "\t\tff = es.std_runs(std_mode,hostname=hostname,debug=verbose)\n",
    "\n",
    "\t\t# load the desired variables \n",
    "\t\tfrom netCDF4 import Dataset\n",
    "\t\tf = Dataset(ff,'r')\n",
    "\t\tlat = f.variables['lat'][:]\n",
    "\t\tlon = f.variables['lon'][:]\n",
    "\t\tlev = f.variables['lev'][:]\n",
    "\t\ttime = f.variables['time'][:]\n",
    "\n",
    "\t\tvariable = E['variable']\n",
    "\t\tif E['variable'] == 'US':\n",
    "\t\t\tvariable = 'U'\n",
    "\t\tif E['variable'] == 'VS':\n",
    "\t\t\tvariable = 'V'\n",
    "\t\tif E['variable'] == 'OLR':\n",
    "\t\t\tvariable = 'FLUT'\n",
    "\t\tVV = f.variables[variable][:]\n",
    "\t\tf.close()\n",
    "\n",
    "\t\t# choose the times corresponding to the daterange in E\n",
    "\t\td0 = E['daterange'][0].timetuple().tm_yday\t# day in the year where we start  \n",
    "\t\tnT = len(E['daterange'])\n",
    "\t\tdf = E['daterange'][nT-1].timetuple().tm_yday\t# day in the year where we start  \n",
    "\n",
    "\t\t# if df<d0, we have to cycle back to the beginning of the year\n",
    "\t\tif df < d0:\n",
    "\t\t\tday_indices = list(range(d0-1,365))+list(range(0,df))\n",
    "\t\telse:\n",
    "\t\t\tday_indices = list(range(d0-1,df))\n",
    "\n",
    "\t\t# also choose the lat, lon, and level ranges corresponding to those in E\n",
    "\t\tif E['levrange'] is not None:\n",
    "\t\t\tif E['levrange'][0] == E['levrange'][1]:\n",
    "\t\t\t\tll = E['levrange'][0]\n",
    "\t\t\t\tidx = (np.abs(lev-ll)).argmin()\n",
    "\t\t\t\tlev2 = lev[idx]\n",
    "\t\t\t\tk1 = idx\n",
    "\t\t\t\tk2 = idx\n",
    "\t\t\telse:\n",
    "\t\t\t\thighest_level_index = (np.abs(lev-E['levrange'][1])).argmin()\n",
    "\t\t\t\tlowest_level_index = (np.abs(lev-E['levrange'][0])).argmin()\n",
    "\t\t\t\t# which index is k1 or k2 depends on the direction of lev \n",
    "\t\t\t\tif highest_level_index > lowest_level_index:\n",
    "\t\t\t\t\tk2 = highest_level_index\n",
    "\t\t\t\t\tk1 = lowest_level_index\n",
    "\t\t\t\tif highest_level_index < lowest_level_index:\n",
    "\t\t\t\t\tk1 = highest_level_index\n",
    "\t\t\t\t\tk2 = lowest_level_index\n",
    "\t\t\t\tlev2 = lev[k1:k2+1]\n",
    "\n",
    "\t\tj2 = (np.abs(lat-E['latrange'][1])).argmin()\n",
    "\t\tj1 = (np.abs(lat-E['latrange'][0])).argmin()\n",
    "\t\tlat2 = lat[j1:j2+1]\n",
    "\t\ti2 = (np.abs(lon-E['lonrange'][1])).argmin()\n",
    "\t\ti1 = (np.abs(lon-E['lonrange'][0])).argmin()\n",
    "\t\tlon2 = lon[i1:i2+1]\n",
    "\n",
    "\t\tif len(VV.shape) == 4:\n",
    "\t\t\tXclim = VV[day_indices,k1:k2+1,j1:j2+1,i1:i2+1]\n",
    "\t\telse:\n",
    "\t\t\tXclim = VV[day_indices,j1:j2+1,i1:i2+1]\n",
    "\n",
    "\t\t# in this case, we don't need to change the daterange  \n",
    "\t\tDRnew = E['daterange']\n",
    "\n",
    "\treturn Xclim,lat,lon,lev,DRnew\n",
    "\n",
    "def ano(E,climatology_option = 'NODA',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tCompute anomaly fields relative to some climatology\n",
    "\n",
    "\tInputs allowed for climatology_option:  \n",
    "\t'NODA': take the ensemble mean of the corresponding no-DA experiment as a 40-year climatology  \n",
    "\t'F_W4_L66': daily climatology of a CESM+WACCM simulation with realistic forcings, 1951-2010\n",
    "\tNone: don't subtract out anything -- just return the regular fields in the same shape as other \"anomalies\"  \n",
    "\t\"\"\"\n",
    "\n",
    "\t# load climatology \n",
    "\tXclim,lat,lon,lev,DR = load_climatology(E,climatology_option,hostname)\n",
    "\n",
    "\t# change the daterange in the anomalies to suit what was found for climatology  \n",
    "\tif len(DR) != len(E['daterange']):\n",
    "\t\tprint('Changing the experiment daterange to the dates found for the requested climatology')\n",
    "\t\tE['daterange'] = DR\n",
    "\t\td1 = DR[0].strftime(\"%Y-%m-%d\")\n",
    "\t\td2 = DR[len(E['daterange'])-1].strftime(\"%Y-%m-%d\")\n",
    "\t\tprint('new daterange goes from '+d1+' to '+d2)\n",
    "\n",
    "\t# some climatologies are only available at daily resolution, so \n",
    "\t# in that case we have to change the daterange in E to be daily  \n",
    "\tif (climatology_option == 'F_W4_L66'):\n",
    "\t\td0 = E['daterange'][0]\n",
    "\t\tdf = E['daterange'][len(E['daterange'])-1]\n",
    "\t\tdays = df-d0\n",
    "\t\tDRnew =  dart.daterange(date_start=d0, periods=days.days+1, DT='1D')\n",
    "\t\tE['daterange'] = DRnew\n",
    "\n",
    "\t# load the desired model fields for the experiment\n",
    "\tXlist = []\t# empty list to hold the fields we retrieve for every day  \n",
    "\tfor date in E['daterange']:\n",
    "\t\tX,lat0,lon0,lev0 = DSS.compute_DART_diagn_from_model_h_files(E,date,hostname=hostname,verbose=verbose)\n",
    "\t\tif X is not None:\n",
    "\t\t\tXs = np.squeeze(X)\n",
    "\t\t\tXlist.append(Xs)\n",
    "\t\t\tlat = lat0\n",
    "\t\t\tlon = lon0\n",
    "\t\t\tlev = lev0\n",
    "\n",
    "\t# check that the right vertical levels were loaded\n",
    "\tif verbose:\n",
    "\t\tprint('------computing daily anomalies for the following vertical levels and variable:-------')\n",
    "\t\tprint(lev)\n",
    "\t\tprint(E['variable'])\n",
    "\n",
    "\t# compute anomalies:\n",
    "\t# for this we turn the model fields into a matrix and subtract from the climatology\n",
    "\tXX = np.concatenate([X[..., np.newaxis] for X in Xlist], axis=len(Xs.shape))\n",
    "\tif climatology_option == None:\n",
    "\t\tAA = XX\n",
    "\telse:\n",
    "\t\t# if the climatology does not have shape lat x lon x lev x time, \n",
    "\t\t# run swapaxes 2x to get it as such  \n",
    "\t\t# NOTE: this is still a kludge and probably wont work with all datasets - check this carefully \n",
    "\t\t# with your own data \n",
    "\t\tXclimS = np.squeeze(Xclim)\n",
    "\t\tnT = len(DRnew)\n",
    "\t\tlastdim = len(XclimS.shape)-1\n",
    "\t\tfor s,ii in zip(XclimS.shape,range(len(XclimS.shape))):\n",
    "\t\t\tif s == nT:\n",
    "\t\t\t\ttime_dim = ii\n",
    "\n",
    "\t\t# if only retrieveing a single date, don't need to do any reshaping\n",
    "\t\t# but might need to squeeze out a length-one time dimension\n",
    "\t\tif nT == 1:\n",
    "\t\t\tXclimR = XclimS\n",
    "\t\t\tXX = np.squeeze(XX)\n",
    "\t\telse:\n",
    "\t\t\t# if time is the last dimension, don't need to reshape Xclim \n",
    "\t\t\tif time_dim == lastdim: \n",
    "\t\t\t\tXclimR = XclimS\n",
    "\t\t\t# if time is the first dimension, need to reshape Xclim\n",
    "\t\t\tif time_dim == 0:\t\n",
    "\t\t\t\tXclim2 = XclimS.swapaxes(0,lastdim)\n",
    "\t\t\t\tXclimR = Xclim2.swapaxes(0,1)\n",
    "\n",
    "\n",
    "\t\tAA = XX-XclimR\n",
    "\n",
    "\treturn AA,XclimR,lat,lon,lev,DR\n",
    "\n",
    "def filter(daily_anomalies,filter_order = 50, return_as_vector = True):\n",
    "\n",
    "\t\"\"\"\n",
    " \tgiven 3D or 2D anomaly fields (e.g. of zonal wind)\n",
    "\tapply a Lanczos filter to isolate the 20-100 day MJO signal \n",
    "\n",
    "\tnote that here the input data have to have DAILY resolution  \n",
    "\n",
    "\tinput filter_order gives the order of the Lanczos Filter - it's defaults is 50 , for a 201-point filter (not sure about this yet-- need to check)  \n",
    "\t\"\"\"\n",
    "\n",
    "\t# turn the anomaly field into a vectors in time \n",
    "\tif len(daily_anomalies.shape)==3:\n",
    "\t\t[n1,n2,nt] = daily_anomalies.shape\n",
    "\t\tL = n1*n2\n",
    "\t\tA = np.reshape(daily_anomalies,(L,nt))\n",
    "\tif len(daily_anomalies.shape)==4:\n",
    "\t\t[n1,n2,n3,nt] = daily_anomalies.shape\n",
    "\t\tL = n1*n2*n3\n",
    "\t\tA = np.reshape(daily_anomalies,(L,nt))\n",
    "\n",
    "\tf_low = 0.01\t\t# 100 days\n",
    "\tf_high = 0.05\t\t# 20 days \n",
    "\tn = filter_order  \n",
    "\n",
    "\tfil = LF.LanczosFilter(\"bp\",f_low,f_high,n)\n",
    "\n",
    "\tFA = A*0\n",
    "\tfor ii in range(len(A)):\n",
    "\t\tFA[ii] = fil.getfiltered(A[ii,:])\n",
    "    \n",
    "\t# if return_as_vector is false, reshape the filtered fields to 3D\n",
    "\tif return_as_vector:\n",
    "\t\tfiltered_anomalies = FA\n",
    "\t\tdaily_anomalies = A\n",
    "\telse:\n",
    "\t\tif len(daily_anomalies.shape)==3:\n",
    "\t\t\tfiltered_anomalies = np.reshape(FA,(n1,n2,nt))\n",
    "\t\tif len(daily_anomalies.shape)==4:\n",
    "\t\t\tfiltered_anomalies = np.reshape(FA,(n1,n2,n3,nt))\n",
    "\n",
    "\treturn daily_anomalies,filtered_anomalies\n",
    "\n",
    "def var(filtered_anomalies,variable_dimensions,return_as_vector=False):\n",
    "\n",
    "\t# compute the variance of 3Dxtime or 2Dxtime anomaly fields that have been \n",
    "\t# Lanczos-filtered to isolate the MJO time window, \n",
    "\t# here the input fields should be a vector varying in time, i.e. with dimension N x nt\n",
    "\t# where N = nlat x nlon x nlev\n",
    "\n",
    "\tN = filtered_anomalies.shape[0]\n",
    "\tVA = np.zeros(shape=(N,1))\n",
    "\n",
    "\tfor ii in range(N):\n",
    "\t\tVA[ii] = np.var(filtered_anomalies[ii,:])\n",
    "\n",
    "\t# if return_as_vector is false, reshape the filtered fields to 3D\n",
    "\tif return_as_vector:\n",
    "\t\tVout = VA\n",
    "\telse:\n",
    "\t\tVout = np.reshape(VA,variable_dimensions[0:2])\n",
    "\n",
    "\treturn(Vout)\n",
    "\n",
    "def aave(region,FA,lat,lon,season,variable_name,averaging_dimension='all'):\n",
    "\n",
    "\t\"\"\"\n",
    "\taverage diagnostic model variables over a region  \n",
    "\t\n",
    "\tINPUTS:  \n",
    "\t+ region: either a pre-defined region (retrieved from function averaging_regions) or \n",
    "\t\tan experiment dictionary, in which case we use the lat and lonrage there  \n",
    "\t+ FA: anomaly field over which to average. For standard MJO diagnostics this field should be \n",
    "\t\tfiltered for the MJO time window  \n",
    "\t+ lat,lon: the lat and lon arrays that go with FA  \n",
    "\t+ variable_name: the name of the variable over which we average  \n",
    "\t\tthis is only relevant if we have a pre-named averaging region  \n",
    "\t+ averaging_dimension: the dimension we average over. There are 3 options:  \n",
    "\t\t all : over lat and lon\n",
    "\t\t lat: over lat only\n",
    "\t\t lon: over lon only\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "\t# retrieve the averaging region limits\n",
    "\tif isinstance(region,dict):\n",
    "\t\t# if 'region' is given by an experiment dictionary, read the lat and lonranges from the dictionary itself  \n",
    "\t\tlatrange = region['latrange']\n",
    "\t\tlonrange = region['lonrange']\n",
    "\telse:\n",
    "\t\t# otherwise, retrieve the right averaging region  \n",
    "\t\tlatrange,lonrange = averaging_regions(region,season,variable_name)\n",
    "\n",
    "\t# figure out how the anomaly field FA is shaped\n",
    "\t# the way FA is calculated, it's last dim is always time  \n",
    "\n",
    "\tshape_tuple = FA.shape\n",
    "\tfor dimlength,ii in zip(shape_tuple,range(len(shape_tuple))):\n",
    "\t\tif dimlength == len(lon):\n",
    "\t\t\tlondim = ii\n",
    "\t\tif dimlength == len(lat):\n",
    "\t\t\tlatdim = ii\n",
    "\n",
    "\n",
    "\t# find the lat and lon indices that those ranges correspond to the region limits\n",
    "\ti1 = (np.abs(lon-lonrange[0])).argmin()\t\n",
    "\ti2 = (np.abs(lon-lonrange[1])).argmin()\t\n",
    "\tj1 = (np.abs(lat-latrange[0])).argmin()\t\n",
    "\tj2 = (np.abs(lat-latrange[1])).argmin()\t\n",
    "\n",
    "\tlat_out = lat[j1:j2+1]\n",
    "\tlon_out = lon[i1:i2+1]\n",
    "\n",
    "\t# select the focus region  \n",
    "\t# here I just brute-forced it, manually checking various array shapes that I've had  \n",
    "\tif (latdim == 0) and (londim == 1):\n",
    "\t\tif len(FA.shape)==2:\n",
    "\t\t\tFAsel = FA[j1:j2+1,i1:i2+1]\n",
    "\t\tif len(FA.shape)==3:\n",
    "\t\t\tFAsel = FA[j1:j2+1,i1:i2+1,:]\n",
    "\tif (latdim == 1) and (londim == 0):\n",
    "\t\tif len(FA.shape)==2:\n",
    "\t\t\tFAsel = FA[i1:i2+1,j1:j2+1,:]\n",
    "\t\tif len(FA.shape)==3:\n",
    "\t\t\tFAsel = FA[i1:i2+1,j1:j2+1,:]\n",
    "\tif (latdim == 1) and (londim == 2) and (len(shape_tuple) == 4):\n",
    "\t\tFAsel = FA[:,j1:j2+1,i1:i2+1,:]\n",
    "\t\n",
    "\t# average  \n",
    "\tif averaging_dimension == \"all\":\n",
    "\t\tFAave1 = np.nanmean(FAsel,axis=latdim,keepdims=True)\n",
    "\t\tFAave2 = np.nanmean(FAave1,axis=londim,keepdims=True)\n",
    "\t\tFAave = np.squeeze(FAave2)\n",
    "\tif averaging_dimension == \"lat\": # meridional mean only\n",
    "\t\tFAave = nanmean(FAsel,axis=latdim)\n",
    "\tif averaging_dimension == \"lon\": # zonal mean only\n",
    "\t\tFAave = nanmean(FAsel,axis=londim)\n",
    "\n",
    "\treturn lat_out,lon_out,FAave\n",
    "\n",
    "def astd(region,FA,lat,lon,season,variable_name,averaging_dimension='all'):\n",
    "\n",
    "\t\"\"\"\n",
    "\tcompute the standard deviations of diagnostic model variables over a region  \n",
    "\t\n",
    "\tINPUTS:  \n",
    "\t+ region: either a pre-defined region (retrieved from function averaging_regions) or \n",
    "\t\tan experiment dictionary, in which case we use the lat and lonrage there  \n",
    "\t+ FA: anomaly field over which to average. For standard MJO diagnostics this field should be \n",
    "\t\tfiltered for the MJO time window  \n",
    "\t+ lat,lon: the lat and lon arrays that go with FA  \n",
    "\t+ variable_name: the name of the variable over which we average  \n",
    "\t\tthis is only relevant if we have a pre-named averaging region  \n",
    "\t+ averaging_dimension: the dimension we compute the STD over. There are 3 options:  \n",
    "\t\t all : over lat and lon\n",
    "\t\t lat: over lat only\n",
    "\t\t lon: over lon only\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "\t# retrieve the averaging region limits\n",
    "\tif isinstance(region,dict):\n",
    "\t\t# if 'region' is given by an experiment dictionary, read the lat and lonranges from the dictionary itself  \n",
    "\t\tlatrange = region['latrange']\n",
    "\t\tlonrange = region['lonrange']\n",
    "\telse:\n",
    "\t\t# otherwise, retrieve the right averaging region  \n",
    "\t\tlatrange,lonrange = averaging_regions(region,season,variable_name)\n",
    "\n",
    "\t# figure out how the anomaly field FA is shaped\n",
    "\t# the way FA is calculated, it's last dim is always time  \n",
    "\n",
    "\tshape_tuple = FA.shape\n",
    "\tfor dimlength,ii in zip(shape_tuple,range(len(shape_tuple))):\n",
    "\t\tif dimlength == len(lon):\n",
    "\t\t\tlondim = ii\n",
    "\t\tif dimlength == len(lat):\n",
    "\t\t\tlatdim = ii\n",
    "\n",
    "\n",
    "\t# find the lat and lon indices that those ranges correspond to the region limits\n",
    "\ti1 = (np.abs(lon-lonrange[0])).argmin()\t\n",
    "\ti2 = (np.abs(lon-lonrange[1])).argmin()\t\n",
    "\tj1 = (np.abs(lat-latrange[0])).argmin()\t\n",
    "\tj2 = (np.abs(lat-latrange[1])).argmin()\t\n",
    "\n",
    "\tlat_out = lat[j1:j2+1]\n",
    "\tlon_out = lon[i1:i2+1]\n",
    "\n",
    "\t# select the focus region  \n",
    "\t# here I just brute-forced it, manually checking various array shapes that I've had  \n",
    "\tif (latdim == 0) and (londim == 1):\n",
    "\t\tif len(FA.shape)==2:\n",
    "\t\t\tFAsel = FA[j1:j2+1,i1:i2+1]\n",
    "\t\tif len(FA.shape)==3:\n",
    "\t\t\tFAsel = FA[j1:j2+1,i1:i2+1,:]\n",
    "\tif (latdim == 1) and (londim == 0):\n",
    "\t\tif len(FA.shape)==2:\n",
    "\t\t\tFAsel = FA[i1:i2+1,j1:j2+1,:]\n",
    "\t\tif len(FA.shape)==3:\n",
    "\t\t\tFAsel = FA[i1:i2+1,j1:j2+1,:]\n",
    "\tif (latdim == 1) and (londim == 2) and (len(shape_tuple) == 4):\n",
    "\t\tFAsel = FA[:,j1:j2+1,i1:i2+1,:]\n",
    "\t\n",
    "\t# average  \n",
    "\tif averaging_dimension == \"all\":\n",
    "\t\tFAstd1 = np.nanstd(FAsel,axis=latdim,keepdims=True)\n",
    "\t\tFAstd2 = np.nanstd(FAstd1,axis=londim,keepdims=True)\n",
    "\t\tFAstd = np.squeeze(FAstd2)\n",
    "\tif averaging_dimension == \"lat\": # meridional std only\n",
    "\t\tFAstd = np.nanstd(FAsel,axis=latdim)\n",
    "\tif averaging_dimension == \"lon\": # zonal std only\n",
    "\t\tFAstd = np.nanstd(FAsel,axis=londim)\n",
    "\n",
    "\treturn lat_out,lon_out,FAstd\n",
    "\n",
    "def averaging_regions(region,season,variable):  \n",
    "\n",
    "\t\"\"\"\n",
    "\tlat and lon limits of the averaging regions for CLIVAR MJO diagnostics\n",
    "\tthese are taken from Waliser et al. 2009 (J. Clim)  \n",
    "\t\"\"\"\n",
    "\n",
    "\tif region is 'WH':\t# this latitude band is used in the Wheeler and Hendon MJO index  \n",
    "\t\tlatrange = [-15,15]\n",
    "\t\tlonrange = [0,360]\n",
    "\t\treturn latrange, lonrange\n",
    "\tif region is 'TB':\n",
    "\t\tlatrange = [-10,10]\n",
    "\t\tlonrange = [0,360]\n",
    "\t\treturn latrange, lonrange\n",
    "\tif region is 'ZB':\n",
    "\t\tlatrange = [-30,30]\n",
    "\t\tlonrange = [80,100]\n",
    "\t\treturn latrange, lonrange\n",
    "\n",
    "\t# variables that count as \"precipitation\"\n",
    "\tprecip_variables = ['OLR','precip','FLUT']\n",
    "\n",
    "\t# regions specific for seasons------\n",
    "\n",
    "\t#boreal winter\n",
    "\tif season is 'winter':\n",
    "\n",
    "\t\t# indian ocean  \n",
    "\t\tif region is 'IO':  \n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tlatrange = [-10,5]\n",
    "\t\t\t\tlonrange = [75,100]\n",
    "\t\t\tif (variable == 'U850'):\n",
    "\t\t\t\tlatrange = [-16.25,-1.25]\n",
    "\t\t\t\tlonrange = [68.75,96.25]\n",
    "\t\t\tif (variable is 'U200'):\n",
    "\t\t\t\tlatrange = [3.75,21.25]\n",
    "\t\t\t\tlonrange = [56.25,78.75]\n",
    "\t\t\n",
    "\t\t# west pacific  \n",
    "\t\tif region is 'WP':  \n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tlatrange = [-20,-5]\n",
    "\t\t\t\tlonrange = [160,185]\n",
    "\t\t\tif (variable is 'U850'):\n",
    "\t\t\t\tlatrange = [-13.75,1.25]\n",
    "\t\t\t\tlonrange = [163.75,191.25]\n",
    "\t\t\tif (variable is 'U200'):\n",
    "\t\t\t\tlatrange = [3.75,21.25]\n",
    "\t\t\t\tlonrange = [123.75,151.25]\n",
    "\t\t\n",
    "\t\t# maritime continent\n",
    "\t\tif region is 'MC':  \n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tlatrange = [-17.5,-2.5]\n",
    "\t\t\t\tlonrange = [115,145]\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint('averaging over the Maritime Continent for zonal winds is not part of the CLIVAR diagnostics.')\n",
    "\t\t\t\treturn \n",
    "\t\t\n",
    "\t\t# east pacific\n",
    "\t\tif region is 'EP':  \n",
    "\t\t\tif (variable in precip_variables) or (variable is 'U850'):\n",
    "\t\t\t\tprint('averaging over the East Pacific for anything other than U200 is not part of the CLIVAR diagnostics.')\n",
    "\t\t\t\treturn \n",
    "\t\t\tif (variable is 'U200'):\n",
    "\t\t\t\tlatrange = [1.25,16.25]\n",
    "\t\t\t\tlonrange = [256.25,278.75]\n",
    "\n",
    "\t# boreal summer\n",
    "\tif season is 'summer':\n",
    "\n",
    "\t\t# indian ocean  \n",
    "\t\tif region is 'IO':  \n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tlatrange = [-10,5]\n",
    "\t\t\t\tlonrange = [75,100]\n",
    "\t\t\tif (variable is 'U850'):\n",
    "\t\t\t\tlatrange = [3.75,21.25],\n",
    "\t\t\t\tlonrange = [68.75,96.25]\n",
    "\t\t\tif (variable is 'U200'):\n",
    "\t\t\t\tlatrange = [1.25,16.25]\n",
    "\t\t\t\tlonrange = [43.75,71.25]\n",
    "\t\n",
    "\t\t# bay of Bengal\n",
    "\t\tif region is 'BB':\n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tlatrange = [10,20]\n",
    "\t\t\t\tlonrange = [80,100]\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint('averaging over the bay of Bengal for anything other than U200 and U850 is not part of the CLIVAR diagnostics.')\n",
    "\t\t\t\treturn \n",
    "\n",
    "\t\t# west pacific  \n",
    "\t\tif region is 'WP':  \n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tlatrange = [10,25]\n",
    "\t\t\t\tlonrange = [115,140]\n",
    "\t\t\tif (variable is 'U850'):\n",
    "\t\t\t\tlatrange = [3.75,21.25]\n",
    "\t\t\t\tlonrange = [118.75,146.25]\n",
    "\t\t\tif (variable is 'U200'):\n",
    "\t\t\t\tlatrange = [3.75,21.25]\n",
    "\t\t\t\tlonrange = [123.75,151.25]\n",
    "\t\t\n",
    "\t\t# maritime continent\n",
    "\t\tif region is 'MC':  \n",
    "\t\t\tprint('averaging over the Maritime Continent for boreal summer is not part of the CLIVAR diagnostics.')\n",
    "\t\t\treturn \n",
    "\t\t\n",
    "\t\t# east pacific\n",
    "\t\tif region is 'EP':  \n",
    "\t\t\tif (variable in precip_variables):\n",
    "\t\t\t\tprint('averaging over the East Pacific for OLD and precip during boreal summer is not part of the CLIVAR diagnostics.')\n",
    "\t\t\t\treturn \n",
    "\t\t\tif (variable is 'U850'):\n",
    "\t\t\t\tlatrange = [6.25,16.25]\n",
    "\t\t\t\tlonrange = [241.25,266.25]\n",
    "\t\t\t\t\n",
    "\t\t\tif (variable is 'U200'):\n",
    "\t\t\t\tlatrange = [1.25,16.25]\n",
    "\t\t\t\tlonrange = [238.75,266.25]\n",
    "\n",
    "\t# throw an error if latrange and lonrange didn't get defined\n",
    "\ttry:\n",
    "\t\tlatrange\n",
    "\t\tlonrange\n",
    "\texcept NameError:\n",
    "\t\tprint('MJO.averaging_regions Nothing defined for region '+region+', season '+season,', and variable '+variable)\n",
    "\t\treturn\n",
    "\n",
    "\treturn latrange,lonrange\t\t\n",
    "\n",
    "def read_RMM_true(date_limits,hostname='taurus'):\n",
    "\n",
    "\t\"\"\"\n",
    "\tRead in the observed real-time multivariate MJO index and return RMM1 and RMM2 \n",
    "\tbetween a start date and end date\n",
    "\n",
    "\tINPUTS:\n",
    "\tdate_limits: a tuple of datetime.datetime objects giving the start and end dates  \n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "\t# read in the real-time operational MJO index  \n",
    "\thostname_not_found = True\n",
    "\tif hostname == 'taurus':\n",
    "\t\thostname_not_found = False\n",
    "\t\tdata_dir = '/data/c1/lneef/MJOindex/'\n",
    "\tfname = 'RMM1RMM2.74toRealtime.txt'\n",
    "\tff = data_dir+fname  \n",
    "\tna_values = [9.9999996E+35,999]\n",
    "\tDF = pd.read_csv(ff,skiprows=2,header=None,delim_whitespace=True,na_values=na_values)\n",
    "\tDF.columns=['Year','Month','Day','RMM1','RMM2','phase','amplitude','description']\n",
    "\tDF.dtype = {'Year':np.int32, 'Month':np.int32, 'Day':np.int32, 'RMM1':np.float64, \n",
    "\t'RMM2':np.float64, 'phase':np.int32, 'amplitude':np.float64, 'description':object}\n",
    "\t\n",
    "\t# remove the rows with bad values from the data frame  \n",
    "\tDF2 = DF.dropna() \n",
    "\n",
    "\t# turn the year, mmonth, and day columns into a datetime array  \n",
    "\t# and collect the dates and RMM values that fit into the date range  \n",
    "\t# there is probably a more elegant way to do this.  \n",
    "\tylist = list(DF2['Year'])\n",
    "\tmlist = list(DF2['Month'])\n",
    "\tdlist = list(DF2['Day'])\n",
    "\trmm1list = list(DF2['RMM1'])\n",
    "\trmm2list = list(DF2['RMM2'])\n",
    "\tdates = []\n",
    "\tRMM1 = []\n",
    "\tRMM2 = []\n",
    "\n",
    "\tfor y,m,d,r1,r2 in zip(ylist,mlist,dlist,rmm1list,rmm2list):\n",
    "\t\td = datetime.datetime(int(y),int(m),int(d))\n",
    "\t\tcond = (d > date_limits[0]) and (d < date_limits[1])\n",
    "\t\tif cond:\n",
    "\t\t\tdates.append(d)\n",
    "\t\t\tRMM1.append(r1)\n",
    "\t\t\tRMM2.append(r2)\n",
    "\n",
    "\n",
    "\tif hostname_not_found:\n",
    "\t\tprint('Do not have file paths set for hostname  ',hostname)\n",
    "\t\treturn\n",
    "\n",
    "\t# return the RMM1 and RMM2 indices  \n",
    "\treturn dates, RMM1, RMM2\n",
    "\n",
    "\n",
    "def compute_RMM(E,climatology_option='NODA',hostname='taurus',verbose=False):\n",
    "\n",
    "\t\"\"\"\n",
    "\tgiven a certain experiment dictionary, compute the Wheeler and Hendon (2004)\n",
    "\tRMM index by projecting the modeled fields onto Wheeler and Hendon's multivariate EOFs.\n",
    "\t\n",
    "\tThe subroutine loops over the dates and times given in E['daterange'] and, for each day,\n",
    "\tcreates a Pandas dataframe that holds the RMM1 and RMM2 values for each DART copy. \n",
    "\tThis datarame is then printed to a CSV file, which is stored under /csv/MJO in that \n",
    "\texperiment's directory. \n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\t# compute the PCs for the desired timespan and list of copies \n",
    "\tRMM1list = []\n",
    "\tRMM2list = []\n",
    "\tbad_copies = []\t\t# start a list of the copies that are unavailable  \n",
    "\n",
    "\tfor copy in copy_list:\n",
    "\t\tif copy == \"operational\":\n",
    "\t\t\tdate_limits = (E['daterange'][0],E['daterange'][len(E['daterange'])-1])\n",
    "\t\t\tdates,RMM1,RMM2 = read_RMM_true(date_limits,hostname='taurus')\n",
    "\t\t\tRMM1list.append(RMM1)\n",
    "\t\t\tRMM2list.append(RMM2)\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tE['copystring'] = copy\n",
    "\t\t\tpc = RMM(E,climatology_option=climatology_option,hostname='taurus',verbose=verbose)\n",
    "\t\t\tif pc is None:\n",
    "\t\t\t\t# if we don't have enough data to compute the RMM index for this experiment, \n",
    "\t\t\t\t# add it to the list of bad copies:\n",
    "\t\t\t\tprint('     Unable to compute RMM index for '+copy)\n",
    "\t\t\t\tbad_copies.append(copy)\n",
    "\t\t\telse:\n",
    "\t\t\t\tRMM1list.append(pc[0,:])\n",
    "\t\t\t\tRMM2list.append(pc[1,:])\n",
    "\n",
    "\t# remove the \"bad\" copies from the list\n",
    "\t[copy_list.remove(bc) for bc in bad_copies]\n",
    "\n",
    "\t# pimp out the plot a little bit  \n",
    "\tplt.plot([-4,4],[-4,4],linewidth=0.2,linestyle='--',color='k')\n",
    "\tplt.plot([-4,4],[4,-4],linewidth=0.2,linestyle='--',color='k')\n",
    "\tplt.plot([-4,4],[0,0],linewidth=0.2,linestyle='--',color='k')\n",
    "\tplt.plot([0,0],[-4,4],linewidth=0.2,linestyle='--',color='k')\n",
    "\tplt.xlim([-4.0,4.0])\n",
    "\tplt.ylim([-4.0,4.0])\n",
    "\n",
    "\t# circle in the center of the plot to denote weak index  \n",
    "\tcircle = plt.Circle((0, 0), radius=1.0, fc='k', ec='k', alpha=0.2)\n",
    "\tplt.gca().add_patch(circle)\n",
    "\n",
    "\t# cycle over copies and plot the two princial components against each other  \n",
    "\tfor copy,RMM1,RMM2 in zip(copy_list,RMM1list,RMM2list):\n",
    "\t\t\n",
    "\t\t# choose the color based on the copy string\n",
    "\t\tif \"ensemble member\" in copy:\n",
    "\t\t\tlcolor = \"#848484\"\n",
    "\t\t\t#lcolor = \"#70B8FF\"\n",
    "\t\t\tplt.plot(RMM1,RMM2,'-',color=lcolor,linewidth=1)\n",
    "\t\tif copy == \"ensemble mean\":\n",
    "\t\t\t#lcolor = \"#636363\"\n",
    "\t\t\tlcolor = \"#70B8FF\"\n",
    "\t\t\t#c = np.linspace(0, 10, RMM1.shape[0])\n",
    "\t\t\t#cmap = plt.cm.jet\n",
    "\t\t\t#plt.scatter(RMM1,RMM2,c=c,cmap=cmap,s=10)\n",
    "\t\t\tplt.plot(RMM1,RMM2,'-',color=lcolor,linewidth=2)\n",
    "\t\tif copy == \"operational\":\n",
    "\t\t\tlcolor = \"#000000\"\n",
    "\t\t\tprint('plotting operational RMM index in black')\n",
    "\t\t\tplt.plot(RMM1,RMM2,'-',color=lcolor,linewidth=2)\n",
    "\n",
    "\t# labels and stuff  \n",
    "\tplt.xlabel('RMM1')\n",
    "\tplt.ylabel('RMM2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
